{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5525cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f16e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 500\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "\n",
    "data_path = 'D:\\\\NLP_data\\\\tam.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c0c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, 'r', encoding = 'utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    #We use tab as the start sequence character\n",
    "    # for the targets, and \\n as end sequence character\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    \n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a05fca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '!',\n",
       " \"'\",\n",
       " ',',\n",
       " '.',\n",
       " '0',\n",
       " '2',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the input characters\n",
    "input_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f17bc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '0',\n",
       " '2',\n",
       " '?',\n",
       " 'C',\n",
       " 'D',\n",
       " 'அ',\n",
       " 'ஆ',\n",
       " 'இ',\n",
       " 'உ',\n",
       " 'ஊ',\n",
       " 'எ',\n",
       " 'ஏ',\n",
       " 'ஒ',\n",
       " 'ஓ',\n",
       " 'க',\n",
       " 'ங',\n",
       " 'ச',\n",
       " 'ஜ',\n",
       " 'ஞ',\n",
       " 'ட',\n",
       " 'ண',\n",
       " 'த',\n",
       " 'ந',\n",
       " 'ன',\n",
       " 'ப',\n",
       " 'ம',\n",
       " 'ய',\n",
       " 'ர',\n",
       " 'ற',\n",
       " 'ல',\n",
       " 'ள',\n",
       " 'ழ',\n",
       " 'வ',\n",
       " 'ஷ',\n",
       " 'ஸ',\n",
       " 'ா',\n",
       " 'ி',\n",
       " 'ீ',\n",
       " 'ு',\n",
       " 'ூ',\n",
       " 'ெ',\n",
       " 'ே',\n",
       " 'ை',\n",
       " 'ொ',\n",
       " 'ோ',\n",
       " '்'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the target characters\n",
    "target_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb878c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I slept.',\n",
       " 'Calm down.',\n",
       " \"I'll walk.\",\n",
       " 'Who is he?',\n",
       " 'Who knows?',\n",
       " 'She smiled.',\n",
       " 'Talk to me!',\n",
       " 'Who is she?',\n",
       " 'Go to sleep.',\n",
       " 'It may rain.',\n",
       " 'She bit him.',\n",
       " 'She hit him.',\n",
       " 'She is kind.',\n",
       " 'She is eight.',\n",
       " 'Where are we?',\n",
       " 'Keep in touch!',\n",
       " 'See you again.',\n",
       " 'Give it to her.',\n",
       " 'I ate too much.',\n",
       " \"I'll see to it.\",\n",
       " \"It's up to you.\",\n",
       " 'Leave it to me.',\n",
       " 'Listen to this!',\n",
       " \"That's the way.\",\n",
       " 'Come and see me.',\n",
       " \"Don't lie to me.\",\n",
       " 'He began to run.',\n",
       " 'He just arrived.',\n",
       " 'He likes to run.',\n",
       " 'How is your dad?',\n",
       " 'I want to sleep.',\n",
       " \"I'm able to run.\",\n",
       " 'Raise your hand.',\n",
       " 'What did he say?',\n",
       " 'When can we eat?',\n",
       " 'Come and help us.',\n",
       " 'He is still here.',\n",
       " 'I have to go now.',\n",
       " 'I know that much.',\n",
       " 'I made a mistake.',\n",
       " 'I walk to school.',\n",
       " \"That's our house.\",\n",
       " 'Those are my CDs.',\n",
       " 'Walk ahead of me.',\n",
       " \"We'll follow you.\",\n",
       " 'Beware of the dog!',\n",
       " 'He came back soon.',\n",
       " 'He has three sons.',\n",
       " 'I know how to ski.',\n",
       " 'I know what to do.',\n",
       " \"I'm kind of happy.\",\n",
       " 'Keep to the right.',\n",
       " 'She began to sing.',\n",
       " 'She decided to go.',\n",
       " 'Do I have to study?',\n",
       " 'He is sure to come.',\n",
       " 'I had to walk home.',\n",
       " 'I have to dress up.',\n",
       " 'I told him to come.',\n",
       " \"I'm short of money.\",\n",
       " 'May I speak to you?',\n",
       " 'She gave it to him.',\n",
       " 'She is kind to him.',\n",
       " 'She sat next to me.',\n",
       " 'Shut up and listen!',\n",
       " 'Tell me what to do.',\n",
       " 'Tom runs very fast.',\n",
       " 'We ran out of food.',\n",
       " 'We started to walk.',\n",
       " 'When does it begin?',\n",
       " 'Are you ready to go?',\n",
       " 'Do you have any gum?',\n",
       " 'Does she play piano?',\n",
       " \"Don't listen to her.\",\n",
       " 'Go and wake Mary up.',\n",
       " 'He seems to know us.',\n",
       " 'I am engaged to her.',\n",
       " 'I have to leave now.',\n",
       " 'I want to go abroad.',\n",
       " \"I'm glad to see you.\",\n",
       " \"I'm proud of my son.\",\n",
       " \"I'm taller than you.\",\n",
       " \"I'm trying to sleep.\",\n",
       " \"It's free of charge.\",\n",
       " \"It's time to get up.\",\n",
       " 'Nobody speaks to me.',\n",
       " 'Roll the ball to me.',\n",
       " 'She boiled the eggs.',\n",
       " 'She danced with him.',\n",
       " 'She gave him a book.',\n",
       " 'She has 2,000 books.',\n",
       " 'This apple is sweet.',\n",
       " 'We swam in the lake.',\n",
       " 'Come home before six.',\n",
       " 'Go and see who it is.',\n",
       " 'I am afraid of bears.',\n",
       " 'I expect him to come.',\n",
       " \"It's a piece of cake.\",\n",
       " 'The boy began to cry.',\n",
       " 'You keep out of this.',\n",
       " 'All of us were silent.',\n",
       " 'Be kind to old people.',\n",
       " 'Beware of pickpockets.',\n",
       " \"Don't drink and drive.\",\n",
       " 'He can read and write.',\n",
       " 'He got a lot of money.',\n",
       " 'He has a lot of money.',\n",
       " 'He is afraid of death.',\n",
       " 'He let go of the rope.',\n",
       " 'I am tired of my work.',\n",
       " 'I got out of the taxi.',\n",
       " 'None of your business.',\n",
       " 'They made fun of Mary.',\n",
       " 'Tom and I are friends.',\n",
       " 'When is your birthday?',\n",
       " 'All of them went there.',\n",
       " 'Can you ride a bicycle?',\n",
       " 'Do you want to be rich?',\n",
       " 'He is afraid of snakes.',\n",
       " 'He is fond of swimming.',\n",
       " 'He went in place of me.',\n",
       " \"He's afraid of the sea.\",\n",
       " \"I'll leave that to you.\",\n",
       " 'It seems she hates you.',\n",
       " 'She got engaged to him.',\n",
       " 'She got married to him.',\n",
       " 'She stood close to him.',\n",
       " \"They're about to leave.\",\n",
       " 'This CD belongs to her.',\n",
       " 'We ran after the thief.',\n",
       " 'What do you plan to do?',\n",
       " 'A square has four sides.',\n",
       " 'Charge it to my account.',\n",
       " 'He asked us to help him.',\n",
       " 'He is known to everyone.',\n",
       " 'He objected to our plan.',\n",
       " 'I just want you to come.',\n",
       " 'I want something to eat.',\n",
       " 'Is he a friend of yours?',\n",
       " 'The news quickly spread.',\n",
       " \"I can't find it anywhere.\",\n",
       " \"I thought you'd be angry.\",\n",
       " 'Please sit here and wait.',\n",
       " 'She went out of the room.',\n",
       " 'Speak slowly and clearly.',\n",
       " 'The sky is full of stars.',\n",
       " 'Come and see me right now.',\n",
       " 'Do you have a lot of pens?',\n",
       " 'Go and sit by your father.',\n",
       " 'He bought a pair of shoes.',\n",
       " 'I live on the bottom floor.',\n",
       " 'I sat between Tom and John.',\n",
       " 'She wore a beautiful dress.',\n",
       " 'When did you come to Japan?',\n",
       " \"Don't tell Tom you're a cop.\",\n",
       " \"Don't think about it. Do it.\",\n",
       " \"Most people think I'm crazy.\",\n",
       " 'I suppose Tom is still alive.',\n",
       " 'She asked him for some money.',\n",
       " 'Tom told me about it himself.',\n",
       " 'Do you know when he will come?',\n",
       " 'He painted a picture of a dog.',\n",
       " 'I arrived ahead of the others.',\n",
       " 'I know every inch of the town.',\n",
       " \"I'm not sharing this with Tom.\",\n",
       " 'She is not afraid of anything.',\n",
       " 'The price of eggs is going up.',\n",
       " 'Tom picked up the soccer ball.',\n",
       " 'What is the price of this cap?',\n",
       " 'Which of them is your brother?',\n",
       " 'He arrived after the bell rang.',\n",
       " 'He was not aware of the danger.',\n",
       " 'My throat hurts when I swallow.',\n",
       " 'The school looks like a prison.',\n",
       " \"I'm not sure how to answer this.\",\n",
       " \"There's no easy way out of here.\",\n",
       " 'Three vicious dogs attacked Tom.',\n",
       " 'Tom was in Australia a year ago.',\n",
       " 'When did the wedding take place?',\n",
       " 'Where do you keep your passport?',\n",
       " \"Because he's sick, he can't come.\",\n",
       " 'Friendship requires mutual trust.',\n",
       " \"He put the ring on Mary's finger.\",\n",
       " 'She glanced through the magazine.',\n",
       " 'Tom has been crying all afternoon.',\n",
       " 'Tom has been in contact with Mary.',\n",
       " 'I want to be a pilot in the future.',\n",
       " 'If Tom ran away, where could he go?',\n",
       " 'I had my pocket picked on the train.',\n",
       " 'He told her something and she smiled.',\n",
       " \"I don't like to go out when it's dark.\",\n",
       " 'When he spoke, everyone became silent.',\n",
       " 'Tom drank with us until after midnight.',\n",
       " 'She has never been in a car driven by him.',\n",
       " 'Tom goes to church with Mary every Sunday.',\n",
       " \"I don't think people use that word anymore.\",\n",
       " 'My younger sister got married in her teens.',\n",
       " 'I wonder why Tom suggested we do that together.',\n",
       " \"Tom says he doesn't think he can do that by himself.\",\n",
       " \"People who live in glass houses shouldn't throw stones.\",\n",
       " \"It's been a long time since I've heard anyone use that word.\",\n",
       " 'If you want your workers to be happy, you need to pay them a decent wage.',\n",
       " \"It's my fault that the cake was burned. I was talking on the phone and didn't notice the time.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the input texts\n",
    "input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9fd957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tநான் தூங்கினேன்.\\n',\n",
       " '\\tஅமைதியாக இருங்கள்\\n',\n",
       " '\\tநான் நடப்பேன்.\\n',\n",
       " '\\tஅவன் யார்?\\n',\n",
       " '\\tயாருக்குத் தெரியும்?\\n',\n",
       " '\\tஅவள் சிரித்தாள்\\n',\n",
       " '\\tஎன்னிடம் பேசு\\n',\n",
       " '\\tஅவள் யார்?\\n',\n",
       " '\\tபோய் தூங்கு\\n',\n",
       " '\\tமழை பெய்யலாம்\\n',\n",
       " '\\tஅவள் அவனைக் கடித்தாள்\\n',\n",
       " '\\tஅவள் அவனைக் அடித்தாள்\\n',\n",
       " '\\tஅவள் அன்பானவள்\\n',\n",
       " '\\tஅவளுக்கு எட்டு வயது\\n',\n",
       " '\\tநாம் எங்கே இருக்கிறோம்?\\n',\n",
       " '\\tதொடர்பில் இரு\\n',\n",
       " '\\tமறுபடியும் சந்திப்போம்\\n',\n",
       " '\\tஅவளிடம் கொடு\\n',\n",
       " '\\tநான் நிறைய சாப்பிட்டேன்\\n',\n",
       " '\\tஅதை நான் பார்க்கிறேன்\\n',\n",
       " '\\tஉன் கையில்தான் இருக்கிறது\\n',\n",
       " '\\tஎன்னிடம் விட்டுவிடு\\n',\n",
       " '\\tஇதைக் கேள்\\n',\n",
       " '\\tஅந்த பக்கம்தான் வழி\\n',\n",
       " '\\tஎன்னை வந்து பார்\\n',\n",
       " '\\tஎன்னிடம் பொய் சொல்லாதே\\n',\n",
       " '\\tஅவன் ஓட ஆரம்பித்தான்\\n',\n",
       " '\\tஅவன் இப்பொழுதுதான் வந்தான்\\n',\n",
       " '\\tஅவன் ஓட விருப்பப் படுகிறான்\\n',\n",
       " '\\tதங்களுடைய தந்தையார் எப்படி இருக்கிறார்கள்?\\n',\n",
       " '\\tநான் தூங்க விரும்புகிறேன்\\n',\n",
       " '\\tஎன்னால் ஓட முடிகிறது\\n',\n",
       " '\\tகையைத் தூக்கு\\n',\n",
       " '\\tஅவன் என்ன சொன்னான்?\\n',\n",
       " '\\tஎப்பொழுது நம்மால் சாப்பிட முடியும்\\n',\n",
       " '\\tவா எங்களுக்கு உதவி செய்\\n',\n",
       " '\\tஅவன் இன்னும் இருக்கிறான்\\n',\n",
       " '\\tநான் இப்பொழுது போக வேண்டும்\\n',\n",
       " '\\tஎனக்கு அவ்வளவு தெரியும்.\\n',\n",
       " '\\tநான் ஒரு தவறு செய்தேன்?\\n',\n",
       " '\\tநான் பள்ளிக்கு நடந்து செல்கிறேன்\\n',\n",
       " '\\tஅது எங்களுடைய வீடு\\n',\n",
       " '\\tஅவைகள் என்னுடைய CD கள்\\n',\n",
       " '\\tஎனக்கு முன்னால் நட\\n',\n",
       " '\\tநாங்கள் உன்னைத் பின்பற்றுவோம் (அ) தொடர்வோம்.\\n',\n",
       " '\\tநாய் ஜாக்கிரதை!\\n',\n",
       " '\\tஅவன் சீக்கிரம் திரும்பி வந்தான்\\n',\n",
       " '\\tஅவருக்கு மூன்று மகன்கள்\\n',\n",
       " '\\tஎப்படி பனியில் சறுக்கி விளையாடுவது என்பது எனக்கு தெரியும்\\n',\n",
       " '\\tஎன்ன செய்வது என்பது எனக்குத் தெரியும்\\n',\n",
       " '\\tநான் ஒரு விதமான மகிழ்ச்சியிலிருக்கிறேன்\\n',\n",
       " '\\tவலது பக்கத்தை கடைப் பிடி\\n',\n",
       " '\\tஅவள் பாட ஆரம்பித்தாள்\\n',\n",
       " '\\tஅவள் போகத் தீர்மானித்தாள்\\n',\n",
       " '\\tநான் படிக்க வேண்டுமா?\\n',\n",
       " '\\tஅவன் வருவது நிச்சயம்\\n',\n",
       " '\\tநான் வீட்டிற்கு நடக்க வேண்டியிருந்தது\\n',\n",
       " '\\tநான் ஆடை அணிய வேண்டும்\\n',\n",
       " '\\tநான் அவனை வரச் சொன்னேன்\\n',\n",
       " '\\tஎன்னிடம் பணம் குறைவாக இருக்கிறது\\n',\n",
       " '\\tநான் உன்னிடம் பேசலாமா?\\n',\n",
       " '\\tஅவள் இதை அவனுக்குக் கொடுத்தாள்\\n',\n",
       " '\\tஅவள் அவனிடம் அன்பாக இருக்கிறாள்\\n',\n",
       " '\\tஅவள் எனக்கு அருகில் அமர்ந்தாள்\\n',\n",
       " '\\tவாயை மூடி கவனி\\n',\n",
       " '\\tநான் என்ன செய்ய வேண்டும் என்று சொல்\\n',\n",
       " '\\tடாம் ரொம்ப வேகமாக ஓடுகிறான்\\n',\n",
       " '\\tஎங்களுக்கு உணவு தட்டுப்பாடு ஏற்பட்டது\\n',\n",
       " '\\tநாங்கள் நடக்க ஆரம்பித்தோம்\\n',\n",
       " '\\tஇது எப்பொழுது ஆரம்பிக்கிறது?\\n',\n",
       " '\\tநீங்கள் போகத் தயாராக இருக்கிறீர்களா?\\n',\n",
       " '\\tஉன்னிடம் ஏதாவது பசை இருக்கிறதா?\\n',\n",
       " '\\tஅவள் பியானோ வாசிக்கிறாளோ?\\n',\n",
       " '\\tஅவள் சொல்வதைக் கேட்காதீர்\\n',\n",
       " '\\tபோய் மேரியை எழுப்பு\\n',\n",
       " '\\tஅவனுக்கு நம்மைப் தெரியும் என்று தோன்றுகிறது\\n',\n",
       " '\\tஎனக்கு அவளோடு நிச்சயமாகியிருக்கு\\n',\n",
       " '\\tநான் இப்பொழுது கிளம்ப வேண்டும்\\n',\n",
       " '\\tநான் வெளி நாட்டிற்குச் செல்ல விரும்புகிறேன்\\n',\n",
       " '\\tஉன்னைப் பார்ப்பதில் நான் மகிழ்ச்சி அடைகிறேன்\\n',\n",
       " '\\tஎன் மகனைப் பற்றி பெருமைப் படுகிறேன்\\n',\n",
       " '\\tநான் உன்னை விட உயரமாக இருக்கிறேன்\\n',\n",
       " '\\tநான் தூங்குவதற்கு முயற்சி செய்து கொண்டிருக்கிறேன்\\n',\n",
       " '\\tஇதற்கு கட்டணமில்லை\\n',\n",
       " '\\tதூக்கத்திலிருந்து எழுவதற்கான நேரம் இது\\n',\n",
       " '\\tஎன் கூட யாரும் பேசுவதில்லை\\n',\n",
       " '\\tபந்தை என்னிடம் உருட்டி விடு\\n',\n",
       " '\\tஅவள் முட்டைகளை வேக வைத்தாள்\\n',\n",
       " '\\tஅவள் அவனோடு நடனம் ஆடினாள்\\n',\n",
       " '\\tஅவள் அவனுக்கு ஒரு புத்தகத்தைக் கொடுத்தாள்\\n',\n",
       " '\\tஅவளிடம் 2000 புத்தகங்கள் உள்ளன\\n',\n",
       " '\\tஇந்த ஆப்பிள் இனிப்பாக இருக்கிறது\\n',\n",
       " '\\tஅவன் ஏரியில் நீச்சலடித்தான்\\n',\n",
       " '\\tஆறு மணிக்கு முன்பு வீட் டிற்கு வா\\n',\n",
       " '\\tபோய் யார் என்று பார்\\n',\n",
       " '\\tஎனக்குக் கரடிகளைக கண்டால் பயம்\\n',\n",
       " '\\tஅவன் வருவான் என எதிர் பார்க்கிறேன்\\n',\n",
       " '\\tஇது ஒரு கேக்கின் துண்டு\\n',\n",
       " '\\tஅந்த பையன் அழ ஆரம்பித்தான்\\n',\n",
       " '\\tநீ இதில் தலையிடாதே\\n',\n",
       " '\\tநாங்கள் அனைவரும் அமைதியாக இருந்தோம்\\n',\n",
       " '\\tவயோதிகர்களிடம் அன்பாக இரு\\n',\n",
       " '\\tஜேப்படிகாரர்களிடம் ஜாக்கிரதையாக இருக்கவும்\\n',\n",
       " '\\tகுடித்துவிட்டு வண்டி ஓட்டாதே\\n',\n",
       " '\\tஅவனுக்கு எழுதப் படிக்கத் தெரியும்\\n',\n",
       " '\\tஅவனுக்கு நிறைய பணம் கிடைத்தது\\n',\n",
       " '\\tஅவனிடம் நிறைய பணமிருக்கிறது\\n',\n",
       " '\\tஅவனுக்கு இறந்து போவதென்றால் பயம்\\n',\n",
       " '\\tஅவன் கயிற்றை விட்டான்\\n',\n",
       " '\\tநான் வேலை பளுவினால் சோர்வாகயிருக்கிறேன்\\n',\n",
       " '\\tநான் டாக்ஸியிலிருந்து இறங்கினேன்\\n',\n",
       " '\\tஇது உங்களுக்கு சம்பந்தமில்லாத விஷயம்\\n',\n",
       " '\\tஅவர்கள் மேரியை கிண்டலடித்தார்கள்\\n',\n",
       " '\\tடாமும் நானும் நண்பர்கள்\\n',\n",
       " '\\tஉங்கள் பிறந்த நாள் எப்போது ?\\n',\n",
       " '\\tஅவர்கள் எல்லோரும் அங்கே சென்றார்கள்\\n',\n",
       " '\\tஉங்களுக்கு சைக்கிள் ஓட்டத் தெரியுமா?\\n',\n",
       " '\\tநீ பணக்காரராக விருப்பமா?\\n',\n",
       " '\\tஅவர்களுக்கு பாம்புகள் என்றால் பயம்\\n',\n",
       " '\\tஅவனுக்கு நீச்சல் மீது பற்று உண்டு\\n',\n",
       " '\\tஅவன் எனக்குப் பதிலாக சேன்றான்\\n',\n",
       " '\\tஅவனுக்குக் கடல் என்றால் பயம்\\n',\n",
       " '\\tநான் அதை உன்னிடம் விட்டு விடுகிறேன்\\n',\n",
       " '\\tஅவள் உன்னை வெறுக்கிற மாதிரி தெரிகிறது\\n',\n",
       " '\\tஅவள் அவனுக்கு நிச்சயிக்கப் பட்டாள்\\n',\n",
       " '\\tஅவள் அவனுக்கு திருமணம் செய்து வைக்கப் பட்டாள்\\n',\n",
       " '\\tஅவனுக்கு நெருக்கமாக நின்றாள்\\n',\n",
       " '\\tஅவர்கள் கிளம்ப இருக்கிறார்கள்\\n',\n",
       " '\\tஇந்த சீடி அவளுக்குச் சொந்தமானது\\n',\n",
       " '\\tநாங்கள் திருடனுக்குப் பின்னால் ஓடினோம்\\n',\n",
       " '\\tநீ என்ன செய்யத் திட்டமிட்டிருக்கிறாய்\\n',\n",
       " '\\tஒரு சதுரத்திற்கு நான்கு பக்கங்கள் உள்ளன\\n',\n",
       " '\\tஎன்னுடைய கணக்கிற்கு மாற்று\\n',\n",
       " '\\tஎங்களை உதவி செய்யும்படி கேட்டான்\\n',\n",
       " '\\tஅவன் ஒவ்வொருவருக்கும் அறிமுகமானவன்\\n',\n",
       " '\\tஎங்களுடைய திட்டத்திற்கு எதிர்ப்புத் தெரிவித்தான்\\n',\n",
       " '\\tநீ வர வேண்டுமென விரும்புகிறேன்\\n',\n",
       " '\\tஎனக்கு சாப்பிட ஏதாவது வேண்டும்\\n',\n",
       " '\\tஅவர் உங்களுடைய நண்பரா?\\n',\n",
       " '\\tசெய்தி வேகமாக பரவியது\\n',\n",
       " '\\tஇது எங்கே இருக்கு என்று என்னால் கண்டுபிடிக்க முடியவில்லை.\\n',\n",
       " '\\tநீ கோபமாக இருப்பாய் என்று எண்ணினேன்.\\n',\n",
       " '\\tஇங்கே அமருங்கள்,தயவு செயது காத்திருங்கள்\\n',\n",
       " '\\tஅவள் அறையை விட்டு வெளியே சென்றாள்\\n',\n",
       " '\\tமெதுவாகவும் தெளிவாகவும் பேசுங்கள்\\n',\n",
       " '\\tவானம் முழுவதும் நட்சத்திரங்கள் இருக்கின்றன\\n',\n",
       " '\\tஉடனே வந்து என்னைப் பார்க்கவும்\\n',\n",
       " '\\tஉன்னிடம் நிறைய பேனாக்கள் இருக்கின்றனவா?\\n',\n",
       " '\\tபோய் உன் தந்தையருகில் அமரவும்\\n',\n",
       " '\\tநான் ஒரு ஜோடி காலணிகளை வாங்கினேன்\\n',\n",
       " '\\tநான் கீழ் தளத்தில் வசிக்கிறேன்\\n',\n",
       " '\\tடாமுக்கும் ஜானுக்கும் இடையில் அமர்ந்தேன்\\n',\n",
       " '\\tஅவள் அழகான ஆடை அணிந்திருந்தாள்\\n',\n",
       " '\\tநீ எப்பொழுது ஜப்பான் வந்தாய்?\\n',\n",
       " '\\tநீ காவலன் என்பதை டாமிடம் சொல்லாதே.\\n',\n",
       " '\\tஅதைப்பற்றி எண்ணிக்கொண்டிருக்காதே. செயல்படு\\n',\n",
       " '\\tநிறைய மக்கள் நான் பைத்தியம் என்று எண்ணுகிறார்கள்\\n',\n",
       " '\\tடாம் இன்னும் உயிருடனிருக்கிறான் என்று எண்ணுகிறேன்.\\n',\n",
       " '\\tஅவனைக் கொஞ்சம் பணம் கேட்டாள்\\n',\n",
       " '\\tடாம் அதைப் பற்றி அவனே என்னிடம் சொன்னான்.\\n',\n",
       " '\\tஅவன் எப்ப வருவான் என்று உனக்குத் தெரியுமா\\n',\n",
       " '\\tஒரு நாயின் படத்தை வரைந்தான்\\n',\n",
       " '\\tமற்றவர்களுக்கு முன்னே நான் வந்தேன்\\n',\n",
       " '\\tஇந்த ஊரின் ஒவ்வொரு அங்குலமும் எனக்குத் தெரியும்\\n',\n",
       " '\\tடாமிடம் நான் இதை பகிர்ந்துகொண்டு இருக்கவில்லை.\\n',\n",
       " '\\tஅவள் எதற்கும் பயப்படுவதில்லை\\n',\n",
       " '\\tமுட்டைகளின் விலை அதிகரித்துக் கொண்டிருக்கிறது\\n',\n",
       " '\\tடாம் கால்பந்தை எடுத்தார்.\\n',\n",
       " '\\tஇந்த தொப்பியின் விலை என்ன?\\n',\n",
       " '\\tஇவர்களில் யார் உன்னுடைய சகோதரர்\\n',\n",
       " '\\tமணி ஒலித்தப் பிறகு அவன் வந்தான்\\n',\n",
       " '\\tஅவன் அபாயத்தை அறிந்திருக்க வில்லை\\n',\n",
       " '\\tசின்ன கேக்குத் துண்டு அவள் தொண்டையில் சிக்கிக் கொண்டது\\n',\n",
       " '\\tஇந்த பள்ளி கூடம் ஒரு சிறைச்சாலையைப் போல இருக்கிறது\\n',\n",
       " '\\tஎப்படி பதில் சொல்வது என்பதில் நான் உறுதியாக இல்லை.\\n',\n",
       " '\\tஇங்கிருந்து வெளியே செல்ல சுலபமான வழியில்லை.\\n',\n",
       " '\\tமூன்று மோசமான நாய்கள் டாமை தாக்கின\\n',\n",
       " '\\tடாம் ஒரு வருடத்திற்கு முன்னால் ஆஸ்திரேலியாவில் இருந்தார்\\n',\n",
       " '\\tகல்யாணம் எப்பொழுது நடைப் பெற்றது\\n',\n",
       " '\\tநீ பாஸ்போர்ட்டைஎங்கே வைத்திருக்கிறாய்?\\n',\n",
       " '\\tஅவனுக்கு உடல் நிலை சரியில்லாததனால் அவனால் வர இயலாது\\n',\n",
       " '\\tநட்புக்குத் தேவை பரஸ்பர நம்பிக்கை\\n',\n",
       " '\\tஅவன் மேரியின் விரலில் மோதிரத்தை அணிவித்தான்\\n',\n",
       " '\\tஅவள் பத்திரிக்கையை மேலோட்டமாகப் பார்த்தாள்\\n',\n",
       " '\\tடாம் மதியம் முழுவதும் அழுதுகொண்டேயிருக்கிறான்.\\n',\n",
       " '\\tடாம் மேரியுடன் தொடர்பிலிருந்துருக்கிறான் அல்லது டாம் மேரியுடன் தொடர்பிலிருக்கிறான்.\\n',\n",
       " '\\tநான் எதிர் காலத்தில் ஒரு விமானியாக விரும்புகிறேன்\\n',\n",
       " '\\tடாம் ஓடிவிட்டால், அவரால் எங்கு செல்ல முடியும்?\\n',\n",
       " '\\tஇரயிலில் என்னிடம் ஜேப்படி அடிக்கப் பட்டிருந்தது\\n',\n",
       " '\\tஅவன் அவளிடம் ஏதோ சொன்னான் மற்றும் அவள் சிரித்தாள்.\\n',\n",
       " '\\tஇருட்டாக இருக்கும் பொழுது நான் வெளியே போக விரும்புவதில்லை.\\n',\n",
       " '\\tஅவன் பேசியப் பொழுது எல்லோரும் அமைதி காத்தார்கள்\\n',\n",
       " '\\tடாம் நள்ளிரவு வரை எங்களுடன் குடித்தார்.\\n',\n",
       " '\\tஅவன் ஒட்டினக் காரில் அவள் எப்பொழுதும் இருந்ததில்லை\\n',\n",
       " '\\tடாம் மேரியுடன் ஒவ்வொரு ஞாயிற்றுக் கிழமையும் தேவாலயத்துக்குச் செல்கிறான்.\\n',\n",
       " '\\tமக்கள் அந்த வார்த்தையைப் பயன் படுத்துவதாக எனக்குத் தெரியவில்லை\\n',\n",
       " '\\tஎன் தங்கை இள வயதிலேய கல்யாணம் செய்து கொண்டாள்\\n',\n",
       " '\\tஏன் டாம் நாமிருவரும் சேர்ந்து செய்வோமென்று பரிந்துரைத்தான் என்று ஆச்சரியமடைகிறேன்.\\n',\n",
       " '\\tஎன் ஒருவனால் மட்டுமே அதை செய்ய முடியாது என்று நினைக்கிறேன் என டாம் கூறினார்\\n',\n",
       " '\\tகண்ணாடி வீட்டில் வசிப்பவகள் கல்லை எறியக் கூடாது\\n',\n",
       " '\\tஒருவர் அந்த வார்த்தையைப் பயன் படுத்துவதைக் கேட்டு ரொம்ப நாளாகிறது\\n',\n",
       " '\\tஉங்களுடைய வேலையாட்கள் மகிழ்ச்சியாக இருக்க வேண்டுமென்றால் நீங்கள் கணிசமான சம்பளம் தர வேண்டும்\\n',\n",
       " '\\tஎன்னுடையத் தவறினால் கேக்கானதுக் கருகிப் போனது.தோலைப் பேசியில் பேசிக் கொண்டிருந்ததால் நேரத்தைக் கவனிக்க வில்லை\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the target texts\n",
    "target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe4c768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae4d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d77913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 203\n",
      "No. of unique input tokens: 53\n",
      "No. of unique output tokens: 54\n",
      "Max sequence length for inputs: 94\n",
      "Max sequene length for outputs: 111\n"
     ]
    }
   ],
   "source": [
    "print('Number of Samples:', len(input_texts))\n",
    "print('No. of unique input tokens:', num_encoder_tokens)\n",
    "print('No. of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequene length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc34b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning token to each and every character\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f240f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " \"'\": 2,\n",
       " ',': 3,\n",
       " '.': 4,\n",
       " '0': 5,\n",
       " '2': 6,\n",
       " '?': 7,\n",
       " 'A': 8,\n",
       " 'B': 9,\n",
       " 'C': 10,\n",
       " 'D': 11,\n",
       " 'F': 12,\n",
       " 'G': 13,\n",
       " 'H': 14,\n",
       " 'I': 15,\n",
       " 'J': 16,\n",
       " 'K': 17,\n",
       " 'L': 18,\n",
       " 'M': 19,\n",
       " 'N': 20,\n",
       " 'P': 21,\n",
       " 'R': 22,\n",
       " 'S': 23,\n",
       " 'T': 24,\n",
       " 'W': 25,\n",
       " 'Y': 26,\n",
       " 'a': 27,\n",
       " 'b': 28,\n",
       " 'c': 29,\n",
       " 'd': 30,\n",
       " 'e': 31,\n",
       " 'f': 32,\n",
       " 'g': 33,\n",
       " 'h': 34,\n",
       " 'i': 35,\n",
       " 'j': 36,\n",
       " 'k': 37,\n",
       " 'l': 38,\n",
       " 'm': 39,\n",
       " 'n': 40,\n",
       " 'o': 41,\n",
       " 'p': 42,\n",
       " 'q': 43,\n",
       " 'r': 44,\n",
       " 's': 45,\n",
       " 't': 46,\n",
       " 'u': 47,\n",
       " 'v': 48,\n",
       " 'w': 49,\n",
       " 'x': 50,\n",
       " 'y': 51,\n",
       " 'z': 52}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b3f176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '.': 7,\n",
       " '0': 8,\n",
       " '2': 9,\n",
       " '?': 10,\n",
       " 'C': 11,\n",
       " 'D': 12,\n",
       " 'அ': 13,\n",
       " 'ஆ': 14,\n",
       " 'இ': 15,\n",
       " 'உ': 16,\n",
       " 'ஊ': 17,\n",
       " 'எ': 18,\n",
       " 'ஏ': 19,\n",
       " 'ஒ': 20,\n",
       " 'ஓ': 21,\n",
       " 'க': 22,\n",
       " 'ங': 23,\n",
       " 'ச': 24,\n",
       " 'ஜ': 25,\n",
       " 'ஞ': 26,\n",
       " 'ட': 27,\n",
       " 'ண': 28,\n",
       " 'த': 29,\n",
       " 'ந': 30,\n",
       " 'ன': 31,\n",
       " 'ப': 32,\n",
       " 'ம': 33,\n",
       " 'ய': 34,\n",
       " 'ர': 35,\n",
       " 'ற': 36,\n",
       " 'ல': 37,\n",
       " 'ள': 38,\n",
       " 'ழ': 39,\n",
       " 'வ': 40,\n",
       " 'ஷ': 41,\n",
       " 'ஸ': 42,\n",
       " 'ா': 43,\n",
       " 'ி': 44,\n",
       " 'ீ': 45,\n",
       " 'ு': 46,\n",
       " 'ூ': 47,\n",
       " 'ெ': 48,\n",
       " 'ே': 49,\n",
       " 'ை': 50,\n",
       " 'ொ': 51,\n",
       " 'ோ': 52,\n",
       " '்': 53}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abfd7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot representation\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype = 'float32')\n",
    "\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff4b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code does One-Hot representation\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            #decoder_target_data will be ahead of one timestep\n",
    "            #and will not include the start character\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a5c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 53)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49160d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an input sentence and processing it\n",
    "\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outpus4ts, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard 'encoder_outputs' and keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ee0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the decoder using 'encoder_states' as initial state\n",
    "decoder_inputs = Input(shape = (None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences and to return\n",
    "# internal states as well. We don't use the return states in the\n",
    "# training model, but we will use them in inference.\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, \n",
    "                                     initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f212ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 162 samples, validate on 41 samples\n",
      "Epoch 1/500\n",
      "162/162 [==============================] - 2s 13ms/step - loss: 3.1814 - accuracy: 0.4662 - val_loss: 2.7874 - val_accuracy: 0.5865\n",
      "Epoch 2/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.7530 - accuracy: 0.7533 - val_loss: 2.2270 - val_accuracy: 0.5922\n",
      "Epoch 3/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1429 - accuracy: 0.7612 - val_loss: 2.0514 - val_accuracy: 0.5906\n",
      "Epoch 4/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1178 - accuracy: 0.7602 - val_loss: 2.3320 - val_accuracy: 0.5895\n",
      "Epoch 5/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1837 - accuracy: 0.7608 - val_loss: 1.9988 - val_accuracy: 0.5926\n",
      "Epoch 6/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0899 - accuracy: 0.7609 - val_loss: 2.1516 - val_accuracy: 0.5920\n",
      "Epoch 7/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1262 - accuracy: 0.7607 - val_loss: 1.7871 - val_accuracy: 0.5928\n",
      "Epoch 8/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1368 - accuracy: 0.7623 - val_loss: 2.0022 - val_accuracy: 0.5933\n",
      "Epoch 9/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0507 - accuracy: 0.7619 - val_loss: 1.9348 - val_accuracy: 0.5939\n",
      "Epoch 10/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0231 - accuracy: 0.7613 - val_loss: 2.6379 - val_accuracy: 0.5878\n",
      "Epoch 11/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.2232 - accuracy: 0.7613 - val_loss: 2.0374 - val_accuracy: 0.5942\n",
      "Epoch 12/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0435 - accuracy: 0.7649 - val_loss: 1.8151 - val_accuracy: 0.5931\n",
      "Epoch 13/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0419 - accuracy: 0.7636 - val_loss: 2.4980 - val_accuracy: 0.5924\n",
      "Epoch 14/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1082 - accuracy: 0.7621 - val_loss: 1.7041 - val_accuracy: 0.5917\n",
      "Epoch 15/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0464 - accuracy: 0.7613 - val_loss: 2.3292 - val_accuracy: 0.5928\n",
      "Epoch 16/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0576 - accuracy: 0.7619 - val_loss: 1.6634 - val_accuracy: 0.5944\n",
      "Epoch 17/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0091 - accuracy: 0.7618 - val_loss: 2.4098 - val_accuracy: 0.5913\n",
      "Epoch 18/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0646 - accuracy: 0.7637 - val_loss: 1.6451 - val_accuracy: 0.5964\n",
      "Epoch 19/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9802 - accuracy: 0.7623 - val_loss: 2.2416 - val_accuracy: 0.5920\n",
      "Epoch 20/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0939 - accuracy: 0.7661 - val_loss: 1.6223 - val_accuracy: 0.5979\n",
      "Epoch 21/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9791 - accuracy: 0.7630 - val_loss: 1.8536 - val_accuracy: 0.5959\n",
      "Epoch 22/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9139 - accuracy: 0.7662 - val_loss: 1.5665 - val_accuracy: 0.5968\n",
      "Epoch 23/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9195 - accuracy: 0.7664 - val_loss: 1.8965 - val_accuracy: 0.5964\n",
      "Epoch 24/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9000 - accuracy: 0.7649 - val_loss: 1.5404 - val_accuracy: 0.6005\n",
      "Epoch 25/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9032 - accuracy: 0.7686 - val_loss: 1.8374 - val_accuracy: 0.5972\n",
      "Epoch 26/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8846 - accuracy: 0.7685 - val_loss: 1.5341 - val_accuracy: 0.5988\n",
      "Epoch 27/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8849 - accuracy: 0.7710 - val_loss: 1.9945 - val_accuracy: 0.5970\n",
      "Epoch 28/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9276 - accuracy: 0.7733 - val_loss: 1.5315 - val_accuracy: 0.6060\n",
      "Epoch 29/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8872 - accuracy: 0.7749 - val_loss: 1.6607 - val_accuracy: 0.5996\n",
      "Epoch 30/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8525 - accuracy: 0.7722 - val_loss: 1.5311 - val_accuracy: 0.6027\n",
      "Epoch 31/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8536 - accuracy: 0.7731 - val_loss: 1.8565 - val_accuracy: 0.5996\n",
      "Epoch 32/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8718 - accuracy: 0.7723 - val_loss: 1.5030 - val_accuracy: 0.6137\n",
      "Epoch 33/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8519 - accuracy: 0.7776 - val_loss: 1.5641 - val_accuracy: 0.6038\n",
      "Epoch 34/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8363 - accuracy: 0.7784 - val_loss: 1.5450 - val_accuracy: 0.6029\n",
      "Epoch 35/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8270 - accuracy: 0.7769 - val_loss: 1.5287 - val_accuracy: 0.5981\n",
      "Epoch 36/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8380 - accuracy: 0.7748 - val_loss: 1.7582 - val_accuracy: 0.6212\n",
      "Epoch 37/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.1593 - accuracy: 0.7811 - val_loss: 1.8764 - val_accuracy: 0.6010\n",
      "Epoch 38/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8332 - accuracy: 0.7778 - val_loss: 1.5973 - val_accuracy: 0.6078\n",
      "Epoch 39/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8206 - accuracy: 0.7816 - val_loss: 1.6061 - val_accuracy: 0.6084\n",
      "Epoch 40/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8169 - accuracy: 0.7837 - val_loss: 1.5892 - val_accuracy: 0.6078\n",
      "Epoch 41/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8122 - accuracy: 0.7839 - val_loss: 1.5272 - val_accuracy: 0.6106\n",
      "Epoch 42/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8078 - accuracy: 0.7846 - val_loss: 1.5619 - val_accuracy: 0.6124\n",
      "Epoch 43/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8054 - accuracy: 0.7883 - val_loss: 1.4453 - val_accuracy: 0.6196\n",
      "Epoch 44/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8076 - accuracy: 0.7853 - val_loss: 1.5037 - val_accuracy: 0.6131\n",
      "Epoch 45/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7950 - accuracy: 0.7868 - val_loss: 1.4754 - val_accuracy: 0.6135\n",
      "Epoch 46/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7934 - accuracy: 0.7888 - val_loss: 1.5313 - val_accuracy: 0.6120\n",
      "Epoch 47/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7979 - accuracy: 0.7838 - val_loss: 1.4893 - val_accuracy: 0.6212\n",
      "Epoch 48/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.8886 - accuracy: 0.7867 - val_loss: 1.4568 - val_accuracy: 0.6251\n",
      "Epoch 49/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7889 - accuracy: 0.7928 - val_loss: 1.4812 - val_accuracy: 0.6221\n",
      "Epoch 50/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7826 - accuracy: 0.7927 - val_loss: 1.5217 - val_accuracy: 0.6223\n",
      "Epoch 51/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7735 - accuracy: 0.7948 - val_loss: 1.5329 - val_accuracy: 0.6260\n",
      "Epoch 52/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7704 - accuracy: 0.7949 - val_loss: 1.4171 - val_accuracy: 0.6210\n",
      "Epoch 53/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7820 - accuracy: 0.7850 - val_loss: 1.4774 - val_accuracy: 0.6181\n",
      "Epoch 54/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7643 - accuracy: 0.7911 - val_loss: 1.4472 - val_accuracy: 0.6262\n",
      "Epoch 55/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7745 - accuracy: 0.7943 - val_loss: 1.3951 - val_accuracy: 0.6394\n",
      "Epoch 56/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7505 - accuracy: 0.7976 - val_loss: 1.3790 - val_accuracy: 0.6265\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7831 - accuracy: 0.7833 - val_loss: 2.3409 - val_accuracy: 0.6010\n",
      "Epoch 58/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 1.0390 - accuracy: 0.7892 - val_loss: 1.3749 - val_accuracy: 0.6423\n",
      "Epoch 59/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7479 - accuracy: 0.8028 - val_loss: 1.3661 - val_accuracy: 0.6447\n",
      "Epoch 60/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7370 - accuracy: 0.8035 - val_loss: 1.3631 - val_accuracy: 0.6449\n",
      "Epoch 61/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7314 - accuracy: 0.8026 - val_loss: 1.3589 - val_accuracy: 0.6429\n",
      "Epoch 62/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7300 - accuracy: 0.8024 - val_loss: 1.3677 - val_accuracy: 0.6313\n",
      "Epoch 63/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7307 - accuracy: 0.8002 - val_loss: 1.3547 - val_accuracy: 0.6434\n",
      "Epoch 64/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7164 - accuracy: 0.8065 - val_loss: 1.3384 - val_accuracy: 0.6506\n",
      "Epoch 65/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7114 - accuracy: 0.8090 - val_loss: 1.3501 - val_accuracy: 0.6456\n",
      "Epoch 66/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7127 - accuracy: 0.8065 - val_loss: 1.3210 - val_accuracy: 0.6456\n",
      "Epoch 67/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7067 - accuracy: 0.8100 - val_loss: 1.3623 - val_accuracy: 0.6423\n",
      "Epoch 68/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.8109 - val_loss: 1.3510 - val_accuracy: 0.6339\n",
      "Epoch 69/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.8052 - val_loss: 1.3187 - val_accuracy: 0.6539\n",
      "Epoch 70/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.8125 - val_loss: 1.2886 - val_accuracy: 0.6506\n",
      "Epoch 71/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6854 - accuracy: 0.8166 - val_loss: 1.3225 - val_accuracy: 0.6508\n",
      "Epoch 72/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6891 - accuracy: 0.8128 - val_loss: 1.3006 - val_accuracy: 0.6412\n",
      "Epoch 73/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6724 - accuracy: 0.8159 - val_loss: 1.2631 - val_accuracy: 0.6695\n",
      "Epoch 74/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6633 - accuracy: 0.8198 - val_loss: 1.2867 - val_accuracy: 0.6583\n",
      "Epoch 75/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6562 - accuracy: 0.8239 - val_loss: 1.2563 - val_accuracy: 0.6647\n",
      "Epoch 76/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6558 - accuracy: 0.8203 - val_loss: 1.2662 - val_accuracy: 0.6640\n",
      "Epoch 77/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6764 - accuracy: 0.8231 - val_loss: 1.8704 - val_accuracy: 0.6383\n",
      "Epoch 78/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6956 - accuracy: 0.8178 - val_loss: 1.2436 - val_accuracy: 0.6695\n",
      "Epoch 79/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6401 - accuracy: 0.8279 - val_loss: 1.2341 - val_accuracy: 0.6634\n",
      "Epoch 80/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6333 - accuracy: 0.8273 - val_loss: 1.2220 - val_accuracy: 0.6737\n",
      "Epoch 81/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6249 - accuracy: 0.8308 - val_loss: 1.2391 - val_accuracy: 0.6697\n",
      "Epoch 82/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6237 - accuracy: 0.8289 - val_loss: 1.1891 - val_accuracy: 0.6746\n",
      "Epoch 83/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6205 - accuracy: 0.8307 - val_loss: 1.2345 - val_accuracy: 0.6656\n",
      "Epoch 84/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6197 - accuracy: 0.8292 - val_loss: 1.1868 - val_accuracy: 0.6812\n",
      "Epoch 85/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6104 - accuracy: 0.8339 - val_loss: 1.2026 - val_accuracy: 0.6728\n",
      "Epoch 86/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6092 - accuracy: 0.8297 - val_loss: 1.1804 - val_accuracy: 0.6741\n",
      "Epoch 87/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6029 - accuracy: 0.8312 - val_loss: 1.1878 - val_accuracy: 0.6803\n",
      "Epoch 88/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5976 - accuracy: 0.8343 - val_loss: 1.1749 - val_accuracy: 0.6788\n",
      "Epoch 89/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.8360 - val_loss: 1.1666 - val_accuracy: 0.6814\n",
      "Epoch 90/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5853 - accuracy: 0.8398 - val_loss: 1.1526 - val_accuracy: 0.6900\n",
      "Epoch 91/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5852 - accuracy: 0.8405 - val_loss: 1.1631 - val_accuracy: 0.6856\n",
      "Epoch 92/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5825 - accuracy: 0.8376 - val_loss: 1.1888 - val_accuracy: 0.6752\n",
      "Epoch 93/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5882 - accuracy: 0.8353 - val_loss: 1.1712 - val_accuracy: 0.6794\n",
      "Epoch 94/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5733 - accuracy: 0.8410 - val_loss: 1.1345 - val_accuracy: 0.6897\n",
      "Epoch 95/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5616 - accuracy: 0.8440 - val_loss: 1.1306 - val_accuracy: 0.6880\n",
      "Epoch 96/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5653 - accuracy: 0.8410 - val_loss: 1.1489 - val_accuracy: 0.6845\n",
      "Epoch 97/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5582 - accuracy: 0.8427 - val_loss: 1.1109 - val_accuracy: 0.6992\n",
      "Epoch 98/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5609 - accuracy: 0.8422 - val_loss: 1.1237 - val_accuracy: 0.6922\n",
      "Epoch 99/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5459 - accuracy: 0.8481 - val_loss: 1.1200 - val_accuracy: 0.6930\n",
      "Epoch 100/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5434 - accuracy: 0.8497 - val_loss: 1.1117 - val_accuracy: 0.6944\n",
      "Epoch 101/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5448 - accuracy: 0.8463 - val_loss: 1.1122 - val_accuracy: 0.6939\n",
      "Epoch 102/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5336 - accuracy: 0.8507 - val_loss: 1.1434 - val_accuracy: 0.6873\n",
      "Epoch 103/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5391 - accuracy: 0.8472 - val_loss: 1.1371 - val_accuracy: 0.6915\n",
      "Epoch 104/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5375 - accuracy: 0.8480 - val_loss: 1.0968 - val_accuracy: 0.6933\n",
      "Epoch 105/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5309 - accuracy: 0.8504 - val_loss: 1.0899 - val_accuracy: 0.6966\n",
      "Epoch 106/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5180 - accuracy: 0.8525 - val_loss: 1.0975 - val_accuracy: 0.7007\n",
      "Epoch 107/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5151 - accuracy: 0.8534 - val_loss: 1.0898 - val_accuracy: 0.6979\n",
      "Epoch 108/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5126 - accuracy: 0.8545 - val_loss: 1.0881 - val_accuracy: 0.7009\n",
      "Epoch 109/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5102 - accuracy: 0.8546 - val_loss: 1.1175 - val_accuracy: 0.6902\n",
      "Epoch 110/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5204 - accuracy: 0.8526 - val_loss: 1.0918 - val_accuracy: 0.7034\n",
      "Epoch 111/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4977 - accuracy: 0.8587 - val_loss: 1.0821 - val_accuracy: 0.6985\n",
      "Epoch 112/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5025 - accuracy: 0.8561 - val_loss: 1.0934 - val_accuracy: 0.6996\n",
      "Epoch 113/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4991 - accuracy: 0.8575 - val_loss: 1.0759 - val_accuracy: 0.7051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.8615 - val_loss: 1.0749 - val_accuracy: 0.7049\n",
      "Epoch 115/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8635 - val_loss: 1.0917 - val_accuracy: 0.6987\n",
      "Epoch 116/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.4882 - accuracy: 0.8600 - val_loss: 1.0976 - val_accuracy: 0.7001\n",
      "Epoch 117/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.8618 - val_loss: 1.1085 - val_accuracy: 0.6963\n",
      "Epoch 118/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4811 - accuracy: 0.8621 - val_loss: 1.0686 - val_accuracy: 0.6972\n",
      "Epoch 119/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4726 - accuracy: 0.8645 - val_loss: 1.0578 - val_accuracy: 0.7082\n",
      "Epoch 120/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4719 - accuracy: 0.8651 - val_loss: 1.0884 - val_accuracy: 0.6994\n",
      "Epoch 121/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.8672 - val_loss: 1.0871 - val_accuracy: 0.7025\n",
      "Epoch 122/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4639 - accuracy: 0.8687 - val_loss: 1.0655 - val_accuracy: 0.7082\n",
      "Epoch 123/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4634 - accuracy: 0.8678 - val_loss: 1.0710 - val_accuracy: 0.7042\n",
      "Epoch 124/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4613 - accuracy: 0.8699 - val_loss: 1.0656 - val_accuracy: 0.7069\n",
      "Epoch 125/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.8685 - val_loss: 1.0554 - val_accuracy: 0.7038\n",
      "Epoch 126/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4550 - accuracy: 0.8713 - val_loss: 1.0812 - val_accuracy: 0.7049\n",
      "Epoch 127/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8690 - val_loss: 1.0747 - val_accuracy: 0.7062\n",
      "Epoch 128/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4448 - accuracy: 0.8739 - val_loss: 1.0833 - val_accuracy: 0.7051\n",
      "Epoch 129/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4451 - accuracy: 0.8731 - val_loss: 1.0726 - val_accuracy: 0.7080\n",
      "Epoch 130/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4409 - accuracy: 0.8743 - val_loss: 1.0867 - val_accuracy: 0.7005\n",
      "Epoch 131/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4370 - accuracy: 0.8753 - val_loss: 1.0863 - val_accuracy: 0.7049\n",
      "Epoch 132/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8740 - val_loss: 1.0745 - val_accuracy: 0.7064\n",
      "Epoch 133/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4289 - accuracy: 0.8764 - val_loss: 1.0816 - val_accuracy: 0.7016\n",
      "Epoch 134/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4314 - accuracy: 0.8754 - val_loss: 1.0882 - val_accuracy: 0.7064\n",
      "Epoch 135/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8767 - val_loss: 1.0977 - val_accuracy: 0.7014\n",
      "Epoch 136/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4280 - accuracy: 0.8780 - val_loss: 1.0376 - val_accuracy: 0.7128\n",
      "Epoch 137/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4263 - accuracy: 0.8767 - val_loss: 1.0647 - val_accuracy: 0.7082\n",
      "Epoch 138/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4130 - accuracy: 0.8822 - val_loss: 1.0749 - val_accuracy: 0.7016\n",
      "Epoch 139/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8804 - val_loss: 1.1024 - val_accuracy: 0.7018\n",
      "Epoch 140/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.8825 - val_loss: 1.0944 - val_accuracy: 0.7047\n",
      "Epoch 141/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.8859 - val_loss: 1.1072 - val_accuracy: 0.7025\n",
      "Epoch 142/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4083 - accuracy: 0.8846 - val_loss: 1.0752 - val_accuracy: 0.7078\n",
      "Epoch 143/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4118 - accuracy: 0.8805 - val_loss: 1.0771 - val_accuracy: 0.7089\n",
      "Epoch 144/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4040 - accuracy: 0.8828 - val_loss: 1.0925 - val_accuracy: 0.7001\n",
      "Epoch 145/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4025 - accuracy: 0.8833 - val_loss: 1.0794 - val_accuracy: 0.7049\n",
      "Epoch 146/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3908 - accuracy: 0.8887 - val_loss: 1.1043 - val_accuracy: 0.7038\n",
      "Epoch 147/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8874 - val_loss: 1.0703 - val_accuracy: 0.7104\n",
      "Epoch 148/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8892 - val_loss: 1.0915 - val_accuracy: 0.7067\n",
      "Epoch 149/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3866 - accuracy: 0.8883 - val_loss: 1.0842 - val_accuracy: 0.7053\n",
      "Epoch 150/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3804 - accuracy: 0.8917 - val_loss: 1.0929 - val_accuracy: 0.7038\n",
      "Epoch 151/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3838 - accuracy: 0.8892 - val_loss: 1.1046 - val_accuracy: 0.7078\n",
      "Epoch 152/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3756 - accuracy: 0.8918 - val_loss: 1.0929 - val_accuracy: 0.7075\n",
      "Epoch 153/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3811 - accuracy: 0.8892 - val_loss: 1.0829 - val_accuracy: 0.7086\n",
      "Epoch 154/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3662 - accuracy: 0.8974 - val_loss: 1.1244 - val_accuracy: 0.7029\n",
      "Epoch 155/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3706 - accuracy: 0.8945 - val_loss: 1.1283 - val_accuracy: 0.7029\n",
      "Epoch 156/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3689 - accuracy: 0.8942 - val_loss: 1.1123 - val_accuracy: 0.7069\n",
      "Epoch 157/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3584 - accuracy: 0.8979 - val_loss: 1.1245 - val_accuracy: 0.7069\n",
      "Epoch 158/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8947 - val_loss: 1.1281 - val_accuracy: 0.7025\n",
      "Epoch 159/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8978 - val_loss: 1.1138 - val_accuracy: 0.7075\n",
      "Epoch 160/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8973 - val_loss: 1.1274 - val_accuracy: 0.7056\n",
      "Epoch 161/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8974 - val_loss: 1.1056 - val_accuracy: 0.7075\n",
      "Epoch 162/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8982 - val_loss: 1.1255 - val_accuracy: 0.7106\n",
      "Epoch 163/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3402 - accuracy: 0.9033 - val_loss: 1.1314 - val_accuracy: 0.7034\n",
      "Epoch 164/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8996 - val_loss: 1.1364 - val_accuracy: 0.7009\n",
      "Epoch 165/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.9023 - val_loss: 1.1254 - val_accuracy: 0.7025\n",
      "Epoch 166/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.9057 - val_loss: 1.1401 - val_accuracy: 0.7038\n",
      "Epoch 167/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.9046 - val_loss: 1.1630 - val_accuracy: 0.6990\n",
      "Epoch 168/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.9024 - val_loss: 1.1332 - val_accuracy: 0.7027\n",
      "Epoch 169/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.9064 - val_loss: 1.1805 - val_accuracy: 0.6994\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 7ms/step - loss: 0.3296 - accuracy: 0.9043 - val_loss: 1.1285 - val_accuracy: 0.7091\n",
      "Epoch 171/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.3241 - accuracy: 0.9090 - val_loss: 1.1727 - val_accuracy: 0.7023\n",
      "Epoch 172/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.9087 - val_loss: 1.1586 - val_accuracy: 0.6990\n",
      "Epoch 173/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3117 - accuracy: 0.9125 - val_loss: 1.1689 - val_accuracy: 0.7003\n",
      "Epoch 174/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3141 - accuracy: 0.9104 - val_loss: 1.1686 - val_accuracy: 0.7080\n",
      "Epoch 175/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.9110 - val_loss: 1.1630 - val_accuracy: 0.6990\n",
      "Epoch 176/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3100 - accuracy: 0.9132 - val_loss: 1.1590 - val_accuracy: 0.7047\n",
      "Epoch 177/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.9132 - val_loss: 1.1712 - val_accuracy: 0.7003\n",
      "Epoch 178/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.9151 - val_loss: 1.1796 - val_accuracy: 0.6998\n",
      "Epoch 179/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3023 - accuracy: 0.9137 - val_loss: 1.1755 - val_accuracy: 0.6937\n",
      "Epoch 180/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2963 - accuracy: 0.9157 - val_loss: 1.1577 - val_accuracy: 0.7069\n",
      "Epoch 181/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.3228 - accuracy: 0.9102 - val_loss: 1.1939 - val_accuracy: 0.7012\n",
      "Epoch 182/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.2980 - accuracy: 0.9160 - val_loss: 1.1563 - val_accuracy: 0.7034\n",
      "Epoch 183/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9213 - val_loss: 1.2059 - val_accuracy: 0.6968\n",
      "Epoch 184/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2922 - accuracy: 0.9167 - val_loss: 1.1674 - val_accuracy: 0.7027\n",
      "Epoch 185/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.2819 - accuracy: 0.9218 - val_loss: 1.2051 - val_accuracy: 0.6987\n",
      "Epoch 186/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.9212 - val_loss: 1.1902 - val_accuracy: 0.7027\n",
      "Epoch 187/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2762 - accuracy: 0.9228 - val_loss: 1.2021 - val_accuracy: 0.7018\n",
      "Epoch 188/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.2727 - accuracy: 0.9244 - val_loss: 1.1962 - val_accuracy: 0.7009\n",
      "Epoch 189/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.9226 - val_loss: 1.2359 - val_accuracy: 0.6957\n",
      "Epoch 190/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2726 - accuracy: 0.9238 - val_loss: 1.2249 - val_accuracy: 0.6990\n",
      "Epoch 191/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2657 - accuracy: 0.9265 - val_loss: 1.2212 - val_accuracy: 0.7020\n",
      "Epoch 192/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2621 - accuracy: 0.9274 - val_loss: 1.2408 - val_accuracy: 0.6994\n",
      "Epoch 193/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2672 - accuracy: 0.9245 - val_loss: 1.2225 - val_accuracy: 0.6963\n",
      "Epoch 194/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.9275 - val_loss: 1.2479 - val_accuracy: 0.6987\n",
      "Epoch 195/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9279 - val_loss: 1.2382 - val_accuracy: 0.7014\n",
      "Epoch 196/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.9295 - val_loss: 1.2435 - val_accuracy: 0.7014\n",
      "Epoch 197/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2525 - accuracy: 0.9302 - val_loss: 1.2443 - val_accuracy: 0.6981\n",
      "Epoch 198/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2490 - accuracy: 0.9312 - val_loss: 1.2486 - val_accuracy: 0.7031\n",
      "Epoch 199/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2509 - accuracy: 0.9294 - val_loss: 1.2436 - val_accuracy: 0.6990\n",
      "Epoch 200/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2387 - accuracy: 0.9342 - val_loss: 1.2503 - val_accuracy: 0.6961\n",
      "Epoch 201/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2406 - accuracy: 0.9348 - val_loss: 1.2623 - val_accuracy: 0.6987\n",
      "Epoch 202/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2355 - accuracy: 0.9364 - val_loss: 1.2708 - val_accuracy: 0.7031\n",
      "Epoch 203/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.9370 - val_loss: 1.2553 - val_accuracy: 0.6970\n",
      "Epoch 204/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2364 - accuracy: 0.9357 - val_loss: 1.2995 - val_accuracy: 0.6908\n",
      "Epoch 205/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2304 - accuracy: 0.9368 - val_loss: 1.2799 - val_accuracy: 0.6957\n",
      "Epoch 206/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.2269 - accuracy: 0.9385 - val_loss: 1.2528 - val_accuracy: 0.7020\n",
      "Epoch 207/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.2412 - accuracy: 0.9321 - val_loss: 1.2816 - val_accuracy: 0.6959\n",
      "Epoch 208/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2191 - accuracy: 0.9412 - val_loss: 1.2928 - val_accuracy: 0.6994\n",
      "Epoch 209/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2202 - accuracy: 0.9395 - val_loss: 1.3203 - val_accuracy: 0.6919\n",
      "Epoch 210/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2223 - accuracy: 0.9386 - val_loss: 1.2714 - val_accuracy: 0.6959\n",
      "Epoch 211/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9404 - val_loss: 1.2988 - val_accuracy: 0.6948\n",
      "Epoch 212/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9429 - val_loss: 1.3292 - val_accuracy: 0.6917\n",
      "Epoch 213/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.2097 - accuracy: 0.9436 - val_loss: 1.3139 - val_accuracy: 0.6966\n",
      "Epoch 214/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.9401 - val_loss: 1.3153 - val_accuracy: 0.7001\n",
      "Epoch 215/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2011 - accuracy: 0.9464 - val_loss: 1.3480 - val_accuracy: 0.6913\n",
      "Epoch 216/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9427 - val_loss: 1.3363 - val_accuracy: 0.6915\n",
      "Epoch 217/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1982 - accuracy: 0.9464 - val_loss: 1.3457 - val_accuracy: 0.6917\n",
      "Epoch 218/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.2010 - accuracy: 0.9468 - val_loss: 1.3370 - val_accuracy: 0.6941\n",
      "Epoch 219/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9475 - val_loss: 1.3637 - val_accuracy: 0.6908\n",
      "Epoch 220/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9477 - val_loss: 1.3544 - val_accuracy: 0.6917\n",
      "Epoch 221/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1986 - accuracy: 0.9464 - val_loss: 1.3599 - val_accuracy: 0.6930\n",
      "Epoch 222/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1948 - accuracy: 0.9464 - val_loss: 1.3792 - val_accuracy: 0.6933\n",
      "Epoch 223/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9503 - val_loss: 1.3357 - val_accuracy: 0.6869\n",
      "Epoch 224/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9459 - val_loss: 1.3687 - val_accuracy: 0.6955\n",
      "Epoch 225/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1829 - accuracy: 0.9514 - val_loss: 1.3455 - val_accuracy: 0.6952\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 6ms/step - loss: 0.1838 - accuracy: 0.9520 - val_loss: 1.3804 - val_accuracy: 0.6946\n",
      "Epoch 227/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9526 - val_loss: 1.3802 - val_accuracy: 0.6966\n",
      "Epoch 228/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1729 - accuracy: 0.9559 - val_loss: 1.3609 - val_accuracy: 0.6950\n",
      "Epoch 229/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1797 - accuracy: 0.9525 - val_loss: 1.4105 - val_accuracy: 0.6908\n",
      "Epoch 230/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9491 - val_loss: 1.3681 - val_accuracy: 0.6941\n",
      "Epoch 231/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1730 - accuracy: 0.9552 - val_loss: 1.4021 - val_accuracy: 0.6941\n",
      "Epoch 232/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1671 - accuracy: 0.9565 - val_loss: 1.3833 - val_accuracy: 0.6919\n",
      "Epoch 233/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1652 - accuracy: 0.9582 - val_loss: 1.4212 - val_accuracy: 0.6889\n",
      "Epoch 234/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9580 - val_loss: 1.4242 - val_accuracy: 0.6946\n",
      "Epoch 235/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1646 - accuracy: 0.9564 - val_loss: 1.4184 - val_accuracy: 0.6845\n",
      "Epoch 236/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1658 - accuracy: 0.9557 - val_loss: 1.4329 - val_accuracy: 0.6957\n",
      "Epoch 237/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1574 - accuracy: 0.9594 - val_loss: 1.4582 - val_accuracy: 0.6867\n",
      "Epoch 238/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9573 - val_loss: 1.4187 - val_accuracy: 0.6886\n",
      "Epoch 239/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1690 - accuracy: 0.9563 - val_loss: 1.4307 - val_accuracy: 0.6926\n",
      "Epoch 240/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1518 - accuracy: 0.9614 - val_loss: 1.4303 - val_accuracy: 0.6924\n",
      "Epoch 241/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1467 - accuracy: 0.9627 - val_loss: 1.4654 - val_accuracy: 0.6871\n",
      "Epoch 242/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1542 - accuracy: 0.9613 - val_loss: 1.4596 - val_accuracy: 0.6906\n",
      "Epoch 243/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9605 - val_loss: 1.4549 - val_accuracy: 0.6895\n",
      "Epoch 244/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.9601 - val_loss: 1.4761 - val_accuracy: 0.6895\n",
      "Epoch 245/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9616 - val_loss: 1.4441 - val_accuracy: 0.6955\n",
      "Epoch 246/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1443 - accuracy: 0.9629 - val_loss: 1.4588 - val_accuracy: 0.6878\n",
      "Epoch 247/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9600 - val_loss: 1.4486 - val_accuracy: 0.6906\n",
      "Epoch 248/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.1387 - accuracy: 0.9649 - val_loss: 1.4598 - val_accuracy: 0.6928\n",
      "Epoch 249/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1408 - accuracy: 0.9639 - val_loss: 1.4930 - val_accuracy: 0.6891\n",
      "Epoch 250/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9659 - val_loss: 1.4902 - val_accuracy: 0.6926\n",
      "Epoch 251/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1390 - accuracy: 0.9646 - val_loss: 1.4888 - val_accuracy: 0.6864\n",
      "Epoch 252/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9650 - val_loss: 1.5242 - val_accuracy: 0.6913\n",
      "Epoch 253/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.1329 - accuracy: 0.9666 - val_loss: 1.4956 - val_accuracy: 0.6836\n",
      "Epoch 254/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.1438 - accuracy: 0.9618 - val_loss: 1.4956 - val_accuracy: 0.6891\n",
      "Epoch 255/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1337 - accuracy: 0.9665 - val_loss: 1.4988 - val_accuracy: 0.6880\n",
      "Epoch 256/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1268 - accuracy: 0.9679 - val_loss: 1.5249 - val_accuracy: 0.6889\n",
      "Epoch 257/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1297 - accuracy: 0.9662 - val_loss: 1.5160 - val_accuracy: 0.6847\n",
      "Epoch 258/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1341 - accuracy: 0.9648 - val_loss: 1.4830 - val_accuracy: 0.6948\n",
      "Epoch 259/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1352 - accuracy: 0.9646 - val_loss: 1.5119 - val_accuracy: 0.6891\n",
      "Epoch 260/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9687 - val_loss: 1.5411 - val_accuracy: 0.6882\n",
      "Epoch 261/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.1172 - accuracy: 0.9698 - val_loss: 1.5317 - val_accuracy: 0.6893\n",
      "Epoch 262/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.1225 - accuracy: 0.9677 - val_loss: 1.5472 - val_accuracy: 0.6875\n",
      "Epoch 263/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1268 - accuracy: 0.9667 - val_loss: 1.5355 - val_accuracy: 0.6900\n",
      "Epoch 264/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1204 - accuracy: 0.9686 - val_loss: 1.5412 - val_accuracy: 0.6849\n",
      "Epoch 265/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1224 - accuracy: 0.9696 - val_loss: 1.5429 - val_accuracy: 0.6900\n",
      "Epoch 266/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.1205 - accuracy: 0.9691 - val_loss: 1.5512 - val_accuracy: 0.6904\n",
      "Epoch 267/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1159 - accuracy: 0.9707 - val_loss: 1.5415 - val_accuracy: 0.6884\n",
      "Epoch 268/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9707 - val_loss: 1.5639 - val_accuracy: 0.6851\n",
      "Epoch 269/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9696 - val_loss: 1.5796 - val_accuracy: 0.6829\n",
      "Epoch 270/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1236 - accuracy: 0.9675 - val_loss: 1.6064 - val_accuracy: 0.6805\n",
      "Epoch 271/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9703 - val_loss: 1.5685 - val_accuracy: 0.6858\n",
      "Epoch 272/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1051 - accuracy: 0.9732 - val_loss: 1.5943 - val_accuracy: 0.6869\n",
      "Epoch 273/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.9728 - val_loss: 1.6073 - val_accuracy: 0.6851\n",
      "Epoch 274/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9709 - val_loss: 1.6225 - val_accuracy: 0.6847\n",
      "Epoch 275/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9734 - val_loss: 1.5996 - val_accuracy: 0.6902\n",
      "Epoch 276/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9729 - val_loss: 1.5702 - val_accuracy: 0.6880\n",
      "Epoch 277/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1157 - accuracy: 0.9689 - val_loss: 1.5996 - val_accuracy: 0.6895\n",
      "Epoch 278/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9720 - val_loss: 1.5969 - val_accuracy: 0.6845\n",
      "Epoch 279/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9751 - val_loss: 1.6232 - val_accuracy: 0.6834\n",
      "Epoch 280/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9750 - val_loss: 1.6208 - val_accuracy: 0.6829\n",
      "Epoch 281/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9741 - val_loss: 1.6362 - val_accuracy: 0.6869\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9735 - val_loss: 1.6233 - val_accuracy: 0.6845\n",
      "Epoch 283/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9725 - val_loss: 1.6599 - val_accuracy: 0.6856\n",
      "Epoch 284/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9748 - val_loss: 1.6346 - val_accuracy: 0.6790\n",
      "Epoch 285/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9746 - val_loss: 1.6480 - val_accuracy: 0.6904\n",
      "Epoch 286/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.1092 - accuracy: 0.9716 - val_loss: 1.6342 - val_accuracy: 0.6831\n",
      "Epoch 287/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.1053 - accuracy: 0.9730 - val_loss: 1.6507 - val_accuracy: 0.6873\n",
      "Epoch 288/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9756 - val_loss: 1.6176 - val_accuracy: 0.6864\n",
      "Epoch 289/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9759 - val_loss: 1.6286 - val_accuracy: 0.6873\n",
      "Epoch 290/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0915 - accuracy: 0.9755 - val_loss: 1.6564 - val_accuracy: 0.6902\n",
      "Epoch 291/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9746 - val_loss: 1.6308 - val_accuracy: 0.6873\n",
      "Epoch 292/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9755 - val_loss: 1.6491 - val_accuracy: 0.6849\n",
      "Epoch 293/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0925 - accuracy: 0.9761 - val_loss: 1.6701 - val_accuracy: 0.6860\n",
      "Epoch 294/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9746 - val_loss: 1.6528 - val_accuracy: 0.6842\n",
      "Epoch 295/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9759 - val_loss: 1.6786 - val_accuracy: 0.6849\n",
      "Epoch 296/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9754 - val_loss: 1.6798 - val_accuracy: 0.6878\n",
      "Epoch 297/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9757 - val_loss: 1.6896 - val_accuracy: 0.6834\n",
      "Epoch 298/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9770 - val_loss: 1.6992 - val_accuracy: 0.6796\n",
      "Epoch 299/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9767 - val_loss: 1.6639 - val_accuracy: 0.6858\n",
      "Epoch 300/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0903 - accuracy: 0.9751 - val_loss: 1.7018 - val_accuracy: 0.6796\n",
      "Epoch 301/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9760 - val_loss: 1.6903 - val_accuracy: 0.6875\n",
      "Epoch 302/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0843 - accuracy: 0.9776 - val_loss: 1.6944 - val_accuracy: 0.6882\n",
      "Epoch 303/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9770 - val_loss: 1.7089 - val_accuracy: 0.6847\n",
      "Epoch 304/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9770 - val_loss: 1.6973 - val_accuracy: 0.6812\n",
      "Epoch 305/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9764 - val_loss: 1.7045 - val_accuracy: 0.6834\n",
      "Epoch 306/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9770 - val_loss: 1.7122 - val_accuracy: 0.6831\n",
      "Epoch 307/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0853 - accuracy: 0.9774 - val_loss: 1.6943 - val_accuracy: 0.6862\n",
      "Epoch 308/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9772 - val_loss: 1.7110 - val_accuracy: 0.6818\n",
      "Epoch 309/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0893 - accuracy: 0.9769 - val_loss: 1.7399 - val_accuracy: 0.6873\n",
      "Epoch 310/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9788 - val_loss: 1.7115 - val_accuracy: 0.6891\n",
      "Epoch 311/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0769 - accuracy: 0.9782 - val_loss: 1.7321 - val_accuracy: 0.6840\n",
      "Epoch 312/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9779 - val_loss: 1.7243 - val_accuracy: 0.6880\n",
      "Epoch 313/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0780 - accuracy: 0.9777 - val_loss: 1.7424 - val_accuracy: 0.6790\n",
      "Epoch 314/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9783 - val_loss: 1.7427 - val_accuracy: 0.6860\n",
      "Epoch 315/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9786 - val_loss: 1.7352 - val_accuracy: 0.6875\n",
      "Epoch 316/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0780 - accuracy: 0.9777 - val_loss: 1.7670 - val_accuracy: 0.6807\n",
      "Epoch 317/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0932 - accuracy: 0.9739 - val_loss: 1.7272 - val_accuracy: 0.6871\n",
      "Epoch 318/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.9769 - val_loss: 1.7074 - val_accuracy: 0.6860\n",
      "Epoch 319/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9785 - val_loss: 1.7336 - val_accuracy: 0.6873\n",
      "Epoch 320/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9786 - val_loss: 1.7372 - val_accuracy: 0.6862\n",
      "Epoch 321/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9798 - val_loss: 1.7495 - val_accuracy: 0.6799\n",
      "Epoch 322/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0726 - accuracy: 0.9784 - val_loss: 1.7790 - val_accuracy: 0.6906\n",
      "Epoch 323/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9782 - val_loss: 1.7760 - val_accuracy: 0.6842\n",
      "Epoch 324/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.9786 - val_loss: 1.7567 - val_accuracy: 0.6829\n",
      "Epoch 325/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0724 - accuracy: 0.9788 - val_loss: 1.7670 - val_accuracy: 0.6834\n",
      "Epoch 326/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9774 - val_loss: 1.8146 - val_accuracy: 0.6796\n",
      "Epoch 327/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0809 - accuracy: 0.9772 - val_loss: 1.7629 - val_accuracy: 0.6849\n",
      "Epoch 328/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0745 - accuracy: 0.9793 - val_loss: 1.7831 - val_accuracy: 0.6851\n",
      "Epoch 329/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9797 - val_loss: 1.8044 - val_accuracy: 0.6842\n",
      "Epoch 330/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9799 - val_loss: 1.7779 - val_accuracy: 0.6867\n",
      "Epoch 331/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9789 - val_loss: 1.7962 - val_accuracy: 0.6829\n",
      "Epoch 332/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.9787 - val_loss: 1.8094 - val_accuracy: 0.6842\n",
      "Epoch 333/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0726 - accuracy: 0.9790 - val_loss: 1.8269 - val_accuracy: 0.6853\n",
      "Epoch 334/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0720 - accuracy: 0.9788 - val_loss: 1.8063 - val_accuracy: 0.6814\n",
      "Epoch 335/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9793 - val_loss: 1.7997 - val_accuracy: 0.6803\n",
      "Epoch 336/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9798 - val_loss: 1.8465 - val_accuracy: 0.6845\n",
      "Epoch 337/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 1.8370 - val_accuracy: 0.6809\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9790 - val_loss: 1.8279 - val_accuracy: 0.6825\n",
      "Epoch 339/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0684 - accuracy: 0.9795 - val_loss: 1.8295 - val_accuracy: 0.6853\n",
      "Epoch 340/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0672 - accuracy: 0.9801 - val_loss: 1.8422 - val_accuracy: 0.6823\n",
      "Epoch 341/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9801 - val_loss: 1.8092 - val_accuracy: 0.6884\n",
      "Epoch 342/500\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.0675 - accuracy: 0.9795 - val_loss: 1.8386 - val_accuracy: 0.6849\n",
      "Epoch 343/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9784 - val_loss: 1.8332 - val_accuracy: 0.6823\n",
      "Epoch 344/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9808 - val_loss: 1.8795 - val_accuracy: 0.6829\n",
      "Epoch 345/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0667 - accuracy: 0.9798 - val_loss: 1.8412 - val_accuracy: 0.6783\n",
      "Epoch 346/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.9776 - val_loss: 1.8540 - val_accuracy: 0.6838\n",
      "Epoch 347/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9808 - val_loss: 1.8471 - val_accuracy: 0.6829\n",
      "Epoch 348/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 0.9795 - val_loss: 1.8520 - val_accuracy: 0.6781\n",
      "Epoch 349/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9798 - val_loss: 1.8631 - val_accuracy: 0.6847\n",
      "Epoch 350/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 1.8829 - val_accuracy: 0.6840\n",
      "Epoch 351/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9796 - val_loss: 1.8844 - val_accuracy: 0.6836\n",
      "Epoch 352/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9786 - val_loss: 1.8475 - val_accuracy: 0.6869\n",
      "Epoch 353/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9761 - val_loss: 1.8339 - val_accuracy: 0.6763\n",
      "Epoch 354/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9803 - val_loss: 1.8397 - val_accuracy: 0.6829\n",
      "Epoch 355/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 1.8620 - val_accuracy: 0.6757\n",
      "Epoch 356/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9801 - val_loss: 1.8391 - val_accuracy: 0.6847\n",
      "Epoch 357/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9793 - val_loss: 1.9163 - val_accuracy: 0.6750\n",
      "Epoch 358/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9783 - val_loss: 1.7781 - val_accuracy: 0.6924\n",
      "Epoch 359/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9806 - val_loss: 1.8075 - val_accuracy: 0.6867\n",
      "Epoch 360/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9803 - val_loss: 1.8478 - val_accuracy: 0.6801\n",
      "Epoch 361/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 1.8326 - val_accuracy: 0.6849\n",
      "Epoch 362/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 1.8462 - val_accuracy: 0.6873\n",
      "Epoch 363/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9806 - val_loss: 1.8698 - val_accuracy: 0.6823\n",
      "Epoch 364/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9793 - val_loss: 1.8599 - val_accuracy: 0.6919\n",
      "Epoch 365/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 1.8613 - val_accuracy: 0.6849\n",
      "Epoch 366/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 1.8676 - val_accuracy: 0.6853\n",
      "Epoch 367/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0605 - accuracy: 0.9804 - val_loss: 1.8780 - val_accuracy: 0.6851\n",
      "Epoch 368/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 1.8893 - val_accuracy: 0.6873\n",
      "Epoch 369/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9803 - val_loss: 1.8927 - val_accuracy: 0.6858\n",
      "Epoch 370/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9804 - val_loss: 1.8600 - val_accuracy: 0.6858\n",
      "Epoch 371/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0629 - accuracy: 0.9804 - val_loss: 1.8852 - val_accuracy: 0.6869\n",
      "Epoch 372/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9807 - val_loss: 1.8844 - val_accuracy: 0.6825\n",
      "Epoch 373/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 0.9793 - val_loss: 1.8995 - val_accuracy: 0.6838\n",
      "Epoch 374/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9806 - val_loss: 1.9021 - val_accuracy: 0.6823\n",
      "Epoch 375/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9805 - val_loss: 1.9058 - val_accuracy: 0.6856\n",
      "Epoch 376/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 1.9424 - val_accuracy: 0.6834\n",
      "Epoch 377/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.9795 - val_loss: 1.8920 - val_accuracy: 0.6814\n",
      "Epoch 378/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0606 - accuracy: 0.9796 - val_loss: 1.9173 - val_accuracy: 0.6838\n",
      "Epoch 379/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 1.9207 - val_accuracy: 0.6840\n",
      "Epoch 380/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0607 - accuracy: 0.9805 - val_loss: 1.9415 - val_accuracy: 0.6853\n",
      "Epoch 381/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 1.9341 - val_accuracy: 0.6827\n",
      "Epoch 382/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.9804 - val_loss: 1.9323 - val_accuracy: 0.6788\n",
      "Epoch 383/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 1.9465 - val_accuracy: 0.6849\n",
      "Epoch 384/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 1.9181 - val_accuracy: 0.6777\n",
      "Epoch 385/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0648 - accuracy: 0.9800 - val_loss: 1.9131 - val_accuracy: 0.6831\n",
      "Epoch 386/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 1.9187 - val_accuracy: 0.6856\n",
      "Epoch 387/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9796 - val_loss: 1.9034 - val_accuracy: 0.6893\n",
      "Epoch 388/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9814 - val_loss: 1.9199 - val_accuracy: 0.6851\n",
      "Epoch 389/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0561 - accuracy: 0.9812 - val_loss: 1.9139 - val_accuracy: 0.6851\n",
      "Epoch 390/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9812 - val_loss: 1.9236 - val_accuracy: 0.6858\n",
      "Epoch 391/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 1.9305 - val_accuracy: 0.6871\n",
      "Epoch 392/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9809 - val_loss: 1.9603 - val_accuracy: 0.6816\n",
      "Epoch 393/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 1.9743 - val_accuracy: 0.6836\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 1.9640 - val_accuracy: 0.6836\n",
      "Epoch 395/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0563 - accuracy: 0.9809 - val_loss: 1.9614 - val_accuracy: 0.6840\n",
      "Epoch 396/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0576 - accuracy: 0.9813 - val_loss: 1.9604 - val_accuracy: 0.6820\n",
      "Epoch 397/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0570 - accuracy: 0.9814 - val_loss: 1.9770 - val_accuracy: 0.6845\n",
      "Epoch 398/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 1.9685 - val_accuracy: 0.6836\n",
      "Epoch 399/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 1.9961 - val_accuracy: 0.6823\n",
      "Epoch 400/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 1.9529 - val_accuracy: 0.6853\n",
      "Epoch 401/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9808 - val_loss: 1.9834 - val_accuracy: 0.6847\n",
      "Epoch 402/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9816 - val_loss: 2.0024 - val_accuracy: 0.6845\n",
      "Epoch 403/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9814 - val_loss: 1.9976 - val_accuracy: 0.6869\n",
      "Epoch 404/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9809 - val_loss: 1.9786 - val_accuracy: 0.6853\n",
      "Epoch 405/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 2.0337 - val_accuracy: 0.6812\n",
      "Epoch 406/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9766 - val_loss: 1.9890 - val_accuracy: 0.6875\n",
      "Epoch 407/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.9791 - val_loss: 1.9270 - val_accuracy: 0.6834\n",
      "Epoch 408/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0562 - accuracy: 0.9821 - val_loss: 1.9319 - val_accuracy: 0.6849\n",
      "Epoch 409/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 1.9422 - val_accuracy: 0.6878\n",
      "Epoch 410/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9827 - val_loss: 1.9499 - val_accuracy: 0.6847\n",
      "Epoch 411/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0538 - accuracy: 0.9820 - val_loss: 1.9500 - val_accuracy: 0.6878\n",
      "Epoch 412/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 1.9647 - val_accuracy: 0.6882\n",
      "Epoch 413/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 1.9685 - val_accuracy: 0.6886\n",
      "Epoch 414/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 1.9569 - val_accuracy: 0.6853\n",
      "Epoch 415/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 1.9834 - val_accuracy: 0.6864\n",
      "Epoch 416/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 1.9746 - val_accuracy: 0.6871\n",
      "Epoch 417/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9822 - val_loss: 1.9725 - val_accuracy: 0.6858\n",
      "Epoch 418/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9825 - val_loss: 2.0002 - val_accuracy: 0.6867\n",
      "Epoch 419/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9820 - val_loss: 2.0009 - val_accuracy: 0.6820\n",
      "Epoch 420/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 2.0105 - val_accuracy: 0.6818\n",
      "Epoch 421/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 2.0088 - val_accuracy: 0.6878\n",
      "Epoch 422/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9820 - val_loss: 2.0229 - val_accuracy: 0.6825\n",
      "Epoch 423/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 2.0018 - val_accuracy: 0.6873\n",
      "Epoch 424/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 2.0470 - val_accuracy: 0.6805\n",
      "Epoch 425/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9821 - val_loss: 2.0436 - val_accuracy: 0.6860\n",
      "Epoch 426/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 2.0445 - val_accuracy: 0.6818\n",
      "Epoch 427/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 2.0250 - val_accuracy: 0.6860\n",
      "Epoch 428/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0541 - accuracy: 0.9818 - val_loss: 2.0441 - val_accuracy: 0.6845\n",
      "Epoch 429/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9829 - val_loss: 2.0262 - val_accuracy: 0.6875\n",
      "Epoch 430/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9823 - val_loss: 2.0234 - val_accuracy: 0.6847\n",
      "Epoch 431/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0533 - accuracy: 0.9825 - val_loss: 2.0378 - val_accuracy: 0.6790\n",
      "Epoch 432/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9825 - val_loss: 2.0453 - val_accuracy: 0.6834\n",
      "Epoch 433/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9823 - val_loss: 2.0610 - val_accuracy: 0.6847\n",
      "Epoch 434/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 2.0381 - val_accuracy: 0.6864\n",
      "Epoch 435/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9818 - val_loss: 2.0193 - val_accuracy: 0.6853\n",
      "Epoch 436/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9831 - val_loss: 2.0633 - val_accuracy: 0.6823\n",
      "Epoch 437/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 2.0885 - val_accuracy: 0.6818\n",
      "Epoch 438/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9822 - val_loss: 2.0339 - val_accuracy: 0.6871\n",
      "Epoch 439/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 2.0485 - val_accuracy: 0.6873\n",
      "Epoch 440/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9764 - val_loss: 1.9974 - val_accuracy: 0.6831\n",
      "Epoch 441/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0569 - accuracy: 0.9817 - val_loss: 1.9793 - val_accuracy: 0.6869\n",
      "Epoch 442/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9830 - val_loss: 1.9762 - val_accuracy: 0.6862\n",
      "Epoch 443/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9829 - val_loss: 1.9925 - val_accuracy: 0.6871\n",
      "Epoch 444/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 2.0049 - val_accuracy: 0.6878\n",
      "Epoch 445/500\n",
      "162/162 [==============================] - 1s 9ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 2.0122 - val_accuracy: 0.6851\n",
      "Epoch 446/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.9823 - val_loss: 2.0273 - val_accuracy: 0.6878\n",
      "Epoch 447/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9824 - val_loss: 2.0284 - val_accuracy: 0.6886\n",
      "Epoch 448/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9824 - val_loss: 2.0331 - val_accuracy: 0.6873\n",
      "Epoch 449/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 2.0565 - val_accuracy: 0.6878\n",
      "Epoch 450/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9824 - val_loss: 2.0431 - val_accuracy: 0.6873\n",
      "Epoch 451/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 2.0431 - val_accuracy: 0.6858\n",
      "Epoch 452/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9819 - val_loss: 2.0437 - val_accuracy: 0.6864\n",
      "Epoch 453/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9823 - val_loss: 2.0828 - val_accuracy: 0.6882\n",
      "Epoch 454/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9822 - val_loss: 2.0719 - val_accuracy: 0.6849\n",
      "Epoch 455/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9814 - val_loss: 2.0538 - val_accuracy: 0.6856\n",
      "Epoch 456/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9824 - val_loss: 2.0496 - val_accuracy: 0.6860\n",
      "Epoch 457/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9824 - val_loss: 2.0589 - val_accuracy: 0.6820\n",
      "Epoch 458/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0513 - accuracy: 0.9825 - val_loss: 2.0707 - val_accuracy: 0.6796\n",
      "Epoch 459/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 2.0042 - val_accuracy: 0.6834\n",
      "Epoch 460/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0592 - accuracy: 0.9807 - val_loss: 1.9715 - val_accuracy: 0.6867\n",
      "Epoch 461/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 1.9967 - val_accuracy: 0.6893\n",
      "Epoch 462/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0491 - accuracy: 0.9835 - val_loss: 1.9956 - val_accuracy: 0.6871\n",
      "Epoch 463/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9833 - val_loss: 2.0130 - val_accuracy: 0.6900\n",
      "Epoch 464/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0489 - accuracy: 0.9826 - val_loss: 2.0276 - val_accuracy: 0.6904\n",
      "Epoch 465/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 2.0269 - val_accuracy: 0.6895\n",
      "Epoch 466/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9834 - val_loss: 2.0379 - val_accuracy: 0.6867\n",
      "Epoch 467/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 2.0504 - val_accuracy: 0.6889\n",
      "Epoch 468/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9829 - val_loss: 2.0345 - val_accuracy: 0.6906\n",
      "Epoch 469/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9828 - val_loss: 2.0365 - val_accuracy: 0.6893\n",
      "Epoch 470/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 2.0576 - val_accuracy: 0.6869\n",
      "Epoch 471/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 2.0515 - val_accuracy: 0.6871\n",
      "Epoch 472/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0498 - accuracy: 0.9833 - val_loss: 2.0721 - val_accuracy: 0.6906\n",
      "Epoch 473/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 2.0796 - val_accuracy: 0.6873\n",
      "Epoch 474/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9834 - val_loss: 2.0630 - val_accuracy: 0.6869\n",
      "Epoch 475/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 2.0853 - val_accuracy: 0.6878\n",
      "Epoch 476/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9840 - val_loss: 2.0902 - val_accuracy: 0.6864\n",
      "Epoch 477/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9833 - val_loss: 2.0938 - val_accuracy: 0.6849\n",
      "Epoch 478/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0488 - accuracy: 0.9839 - val_loss: 2.0971 - val_accuracy: 0.6851\n",
      "Epoch 479/500\n",
      "162/162 [==============================] - 1s 8ms/step - loss: 0.0478 - accuracy: 0.9839 - val_loss: 2.0981 - val_accuracy: 0.6873\n",
      "Epoch 480/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 2.1064 - val_accuracy: 0.6867\n",
      "Epoch 481/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 2.0777 - val_accuracy: 0.6882\n",
      "Epoch 482/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 2.0756 - val_accuracy: 0.6845\n",
      "Epoch 483/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9842 - val_loss: 2.0686 - val_accuracy: 0.6840\n",
      "Epoch 484/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0477 - accuracy: 0.9838 - val_loss: 2.1117 - val_accuracy: 0.6803\n",
      "Epoch 485/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0497 - accuracy: 0.9833 - val_loss: 2.1356 - val_accuracy: 0.6820\n",
      "Epoch 486/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 2.0773 - val_accuracy: 0.6858\n",
      "Epoch 487/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 2.0056 - val_accuracy: 0.6853\n",
      "Epoch 488/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9839 - val_loss: 2.0218 - val_accuracy: 0.6867\n",
      "Epoch 489/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 2.0289 - val_accuracy: 0.6864\n",
      "Epoch 490/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 2.0428 - val_accuracy: 0.6867\n",
      "Epoch 491/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 2.0389 - val_accuracy: 0.6864\n",
      "Epoch 492/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9836 - val_loss: 2.0497 - val_accuracy: 0.6886\n",
      "Epoch 493/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9840 - val_loss: 2.0577 - val_accuracy: 0.6889\n",
      "Epoch 494/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0499 - accuracy: 0.9833 - val_loss: 2.0736 - val_accuracy: 0.6871\n",
      "Epoch 495/500\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.0496 - accuracy: 0.9835 - val_loss: 2.0788 - val_accuracy: 0.6897\n",
      "Epoch 496/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9837 - val_loss: 2.0730 - val_accuracy: 0.6867\n",
      "Epoch 497/500\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 2.0788 - val_accuracy: 0.6922\n",
      "Epoch 498/500\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 2.0822 - val_accuracy: 0.6917\n",
      "Epoch 499/500\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 2.1121 - val_accuracy: 0.6891\n",
      "Epoch 500/500\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9833 - val_loss: 2.0939 - val_accuracy: 0.6895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x144c0f53fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model that will turn 'encoder_input_data' &\n",
    "# 'decoder_input_data' into 'decoder_target_data'\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size = batch_size, epochs = epochs,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30b2bfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I slept.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Calm down.\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: I'll walk.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Who is he?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Who knows?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: She smiled.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Talk to me!\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Who is she?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Go to sleep.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: It may rain.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: She bit him.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She hit him.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She is kind.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She is eight.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Where are we?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Keep in touch!\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: See you again.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Give it to her.\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: I ate too much.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'll see to it.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: It's up to you.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Leave it to me.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Listen to this!\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: That's the way.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Come and see me.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: Don't lie to me.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: He began to run.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: He just arrived.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: He likes to run.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: How is your dad?\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: I want to sleep.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'm able to run.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Raise your hand.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: What did he say?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: When can we eat?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Come and help us.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: He is still here.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: I have to go now.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I know that much.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I made a mistake.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I walk to school.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: That's our house.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Those are my CDs.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Walk ahead of me.\n",
      "Decoded sentence: நான் ஒரு தவறு செய்தேன்?\n",
      "\n",
      "-\n",
      "Input sentence: We'll follow you.\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Beware of the dog!\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: He came back soon.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: He has three sons.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: I know how to ski.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I know what to do.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I'm kind of happy.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Keep to the right.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She began to sing.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She decided to go.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Do I have to study?\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: He is sure to come.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: I had to walk home.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I have to dress up.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I told him to come.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'm short of money.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: May I speak to you?\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: She gave it to him.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She is kind to him.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She sat next to me.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Shut up and listen!\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Tell me what to do.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Tom runs very fast.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: We ran out of food.\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: We started to walk.\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: When does it begin?\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Are you ready to go?\n",
      "Decoded sentence: நான் ஒரு தவறு செய்தேன்?\n",
      "\n",
      "-\n",
      "Input sentence: Do you have any gum?\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Does she play piano?\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: Don't listen to her.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Go and wake Mary up.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: He seems to know us.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: I am engaged to her.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I have to leave now.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: I want to go abroad.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'm glad to see you.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'm proud of my son.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'm taller than you.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I'm trying to sleep.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: It's free of charge.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: It's time to get up.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Nobody speaks to me.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: Roll the ball to me.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: She boiled the eggs.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She danced with him.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She gave him a book.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: She has 2,000 books.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n",
      "-\n",
      "Input sentence: This apple is sweet.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: We swam in the lake.\n",
      "Decoded sentence: அவன் சீக்கிரம் திரும்பி வந்தான்\n",
      "\n",
      "-\n",
      "Input sentence: Come home before six.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: Go and see who it is.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: I am afraid of bears.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: I expect him to come.\n",
      "Decoded sentence: அவன் எனக்குப் பதிலாக சேன்றான்\n",
      "\n",
      "-\n",
      "Input sentence: It's a piece of cake.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: The boy began to cry.\n",
      "Decoded sentence: நான் தூங்க விரும்புகிறேன்\n",
      "\n",
      "-\n",
      "Input sentence: You keep out of this.\n",
      "Decoded sentence: அவள் அவனைக் கடித்தாள்\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next: inference mode (sampling)\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "#  and a 'start of sequence' token as target\n",
    "# output will be the next target token\n",
    "# 3) repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape = (latent_dim,))\n",
    "decoder_state_input_c = Input(shape = (latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, \n",
    "                                                 initial_state = decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, \n",
    "                      [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to something readable\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode input as state vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    \n",
    "    # populate the first character of target sequence with start character\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "    \n",
    "    # sampling loop for a batch of sequernces\n",
    "    # (to simplify, here we assume a batch size of 1)\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        # Exit condition: either hit max length or find stop character\n",
    "        if (sampled_char == '\\n' or \n",
    "            len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set) for trying out decoding\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a857438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
